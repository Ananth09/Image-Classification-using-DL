{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPWQhk3W9JB8iUWxVXfmoZJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananth09/Image-Classification-using-DL/blob/main/imgclassify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3OOY3MPsQwG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqYc9JdWsTOy",
        "outputId": "11936bba-0f28-473a-a488-2be232cb15a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "CFf8sMG1sWKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/img_class/'\n",
        "\n",
        "#parameters\n",
        "batch_size = 17\n",
        "image_size = (224, 224)\n",
        "num_epochs = 31"
      ],
      "metadata": {
        "id": "R77lqwgFsWHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    validation_split = 0.15\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "INRcQ3QzsWFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXdPUX2WsWCw",
        "outputId": "aca7238c-7c36-4be3-e026-a73058f2b05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ne7wsL9sWAZ",
        "outputId": "fae908c1-6bfa-4336-999b-dab2a0132bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 131 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.ResNet101V2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfXRvUF5sV9w",
        "outputId": "7b36447f-5cd1-41ae-c63a-3d91217dd147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171317808/171317808 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "flatten_layer = Flatten()(base_model.layers[-1].output)\n",
        "output_layer=Dense(1, activation = 'sigmoid')(flatten_layer)\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)"
      ],
      "metadata": {
        "id": "ZuGq-VCqsV7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "HSAYyjeqsV4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_generator,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2O7njZJsV2l",
        "outputId": "e7ac8009-0231-4a28-ba88-d46506c6c56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "45/45 [==============================] - 288s 5s/step - loss: 0.3190 - accuracy: 0.8720 - val_loss: 0.8266 - val_accuracy: 0.8015\n",
            "Epoch 2/31\n",
            "45/45 [==============================] - 11s 253ms/step - loss: 0.0911 - accuracy: 0.9733 - val_loss: 0.2273 - val_accuracy: 0.9237\n",
            "Epoch 3/31\n",
            "45/45 [==============================] - 11s 253ms/step - loss: 0.0688 - accuracy: 0.9733 - val_loss: 0.1126 - val_accuracy: 0.9618\n",
            "Epoch 4/31\n",
            "45/45 [==============================] - 11s 253ms/step - loss: 0.0953 - accuracy: 0.9720 - val_loss: 0.1766 - val_accuracy: 0.9389\n",
            "Epoch 5/31\n",
            "45/45 [==============================] - 12s 255ms/step - loss: 0.0660 - accuracy: 0.9760 - val_loss: 0.3235 - val_accuracy: 0.9542\n",
            "Epoch 6/31\n",
            "45/45 [==============================] - 12s 254ms/step - loss: 0.0820 - accuracy: 0.9760 - val_loss: 0.1898 - val_accuracy: 0.9389\n",
            "Epoch 7/31\n",
            "45/45 [==============================] - 12s 255ms/step - loss: 0.0260 - accuracy: 0.9947 - val_loss: 0.0755 - val_accuracy: 0.9695\n",
            "Epoch 8/31\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.0735 - accuracy: 0.9747 - val_loss: 0.1728 - val_accuracy: 0.9542\n",
            "Epoch 9/31\n",
            "45/45 [==============================] - 11s 254ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 0.2794 - val_accuracy: 0.9237\n",
            "Epoch 10/31\n",
            "45/45 [==============================] - 11s 254ms/step - loss: 0.0439 - accuracy: 0.9893 - val_loss: 0.1002 - val_accuracy: 0.9695\n",
            "Epoch 11/31\n",
            "45/45 [==============================] - 11s 253ms/step - loss: 0.1045 - accuracy: 0.9680 - val_loss: 0.1373 - val_accuracy: 0.9618\n",
            "Epoch 12/31\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0601 - accuracy: 0.9747 - val_loss: 0.2158 - val_accuracy: 0.9542\n",
            "Epoch 13/31\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 0.1787 - val_accuracy: 0.9618\n",
            "Epoch 14/31\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.0205 - accuracy: 0.9920 - val_loss: 0.3435 - val_accuracy: 0.9008\n",
            "Epoch 15/31\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0242 - accuracy: 0.9893 - val_loss: 0.1050 - val_accuracy: 0.9542\n",
            "Epoch 16/31\n",
            "45/45 [==============================] - 12s 255ms/step - loss: 0.0176 - accuracy: 0.9933 - val_loss: 0.1197 - val_accuracy: 0.9771\n",
            "Epoch 17/31\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.0386 - accuracy: 0.9907 - val_loss: 0.1360 - val_accuracy: 0.9695\n",
            "Epoch 18/31\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.1898 - val_accuracy: 0.9695\n",
            "Epoch 19/31\n",
            "45/45 [==============================] - 11s 254ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.1614 - val_accuracy: 0.9618\n",
            "Epoch 20/31\n",
            "45/45 [==============================] - 11s 253ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.3060 - val_accuracy: 0.9618\n",
            "Epoch 21/31\n",
            "45/45 [==============================] - 12s 255ms/step - loss: 0.0090 - accuracy: 0.9960 - val_loss: 0.3736 - val_accuracy: 0.9847\n",
            "Epoch 22/31\n",
            "45/45 [==============================] - 11s 252ms/step - loss: 0.0108 - accuracy: 0.9987 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 23/31\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 0.0666 - val_accuracy: 0.9695\n",
            "Epoch 24/31\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1843 - val_accuracy: 0.9618\n",
            "Epoch 25/31\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.1417 - val_accuracy: 0.9695\n",
            "Epoch 26/31\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 0.0370 - val_accuracy: 0.9924\n",
            "Epoch 27/31\n",
            "45/45 [==============================] - 11s 254ms/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 1.2178 - val_accuracy: 0.6947\n",
            "Epoch 28/31\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.0390 - accuracy: 0.9827 - val_loss: 0.1179 - val_accuracy: 0.9771\n",
            "Epoch 29/31\n",
            "45/45 [==============================] - 12s 255ms/step - loss: 0.0296 - accuracy: 0.9960 - val_loss: 0.0940 - val_accuracy: 0.9695\n",
            "Epoch 30/31\n",
            "45/45 [==============================] - 11s 252ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.2767 - val_accuracy: 0.9466\n",
            "Epoch 31/31\n",
            "45/45 [==============================] - 11s 252ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.6788 - val_accuracy: 0.8702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "cSB6dFO88dEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation dataset\n",
        "val_loss, val_accuracy = model.evaluate(val_generator, verbose=1)\n",
        "\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY1y3S0qtspL",
        "outputId": "9f452038-83fb-4737-9da8-eb277373934a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 2s 209ms/step - loss: 0.5162 - accuracy: 0.8473\n",
            "Validation Loss: 0.5162\n",
            "Validation Accuracy: 84.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('resnet101.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWkbHE_GDiic",
        "outputId": "3934ba80-4dcd-44a5-be63-c5bbe89ae8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "RmHZxX3wGvS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "custom_image_path = '/content/drive/MyDrive/test1/0005.jpg'\n",
        "custom_image = load_img(custom_image_path, target_size=(224, 224))\n",
        "custom_image = img_to_array(custom_image)\n",
        "custom_image = custom_image / 255.0  # Normalize pixel values\n",
        "custom_image = custom_image.reshape(1, 224, 224, 3)  # Reshape for model input\n"
      ],
      "metadata": {
        "id": "sfNNKSnKsV0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "prediction = model.predict(custom_image)\n",
        "print(prediction)\n",
        "# Interpret the prediction\n",
        "if prediction > 0.5:\n",
        "    result = \"lifestyle\"\n",
        "else:\n",
        "    result = \"plain_background\"\n",
        "\n",
        "print(f\"The predicted class is: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxUbxIQisVx6",
        "outputId": "f20a6f2b-2b37-4c12-9b1c-ec74d84ba431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[1.]]\n",
            "The predicted class is: lifestyle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "folder_path = '/content/drive/MyDrive/test_for_wrong'\n"
      ],
      "metadata": {
        "id": "zmj6F18px4dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "plain_background_paths=[]\n",
        "liffes=[]\n",
        "life=0\n",
        "plain=0\n",
        "for filename in os.listdir(folder_path):\n",
        "  if filename.endswith('.jpg'):\n",
        "    #if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        custom_image = load_img(image_path, target_size=(224, 224))\n",
        "        custom_image = img_to_array(custom_image)\n",
        "        custom_image = custom_image / 255.0\n",
        "        custom_image = custom_image.reshape(1, 224, 224, 3)\n",
        "\n",
        "        # Predict using your model\n",
        "        prediction = model.predict(custom_image)\n",
        "        print(prediction)\n",
        "        # Interpret the prediction\n",
        "        if prediction < 0.5:\n",
        "            result = \"plain_background\"\n",
        "            plain_background_paths.append(image_path)\n",
        "            plain += 1\n",
        "        else:\n",
        "            result = \"lifestyle\"\n",
        "            liffes.append(image_path)\n",
        "            life += 1\n",
        "\n",
        "print(f\"Number of 'lifestyle' images: {life}\")\n",
        "print(f\"Number of 'plain_background' images: {plain}\")\n",
        "print(\"Paths of 'plain_background' images:\")\n",
        "for path in plain_background_paths:\n",
        "    print(path)\n",
        "print(\"Paths of 'lifestyle' images:\")\n",
        "\n",
        "for path in liffes:\n",
        "    print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlU5l0p1sVvg",
        "outputId": "50dd242b-8035-44e4-810e-7cb30d8d6844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "[[5.208779e-07]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[0.9999888]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[0.9999995]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.9999995]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.9999857]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.83969855]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.99903715]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[0.9999999]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.9999999]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[0.9999186]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.99992967]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[0.9999907]]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.9987326]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.9955226]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.9996605]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[0.9999777]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[0.609317]]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.9888869]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[1.]]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[0.99999547]]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[2.4670532e-08]]\n",
            "Number of 'lifestyle' images: 72\n",
            "Number of 'plain_background' images: 2\n",
            "Paths of 'plain_background' images:\n",
            "/content/drive/MyDrive/test_for_wrong/1e2b6729-17ad-4f7b-891d-2df8c5d55ca31677065948623-Roadster-Men-Black-Dial--Grey-Straps-Analogue--Digital-Multi-1.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/002_87c38e7a.jpg\n",
            "Paths of 'lifestyle' images:\n",
            "/content/drive/MyDrive/test_for_wrong/026_9d887c5a.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/025_77a8e80c.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/031_ff9ac80a.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/029_d2e832fb.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/022_f9a65fd5.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/020_3153dca1.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/023_fd84965f.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/034_1405abff.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/028_73930b8d.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/027_35ce156b.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/024_7c5d5558.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/051_af056bf7.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/052_d0cf4473.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/057_c7ada3ba.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/056_04793ead.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/055_899fafb0.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/071_15023b36.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/058_595a278c.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/069_15e9ef4b.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/066_1de4ad46.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/070_0c217131.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/074_6a464d80.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/080_5ad77f3a.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/079_411644fd.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/086_1f35df1f.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/078_6b3ec48a.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/084_00419fad.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/075_8ea86f61.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/093_8888d952.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/087_263bdb48.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/097_60debdde.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/107_02cabddb.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/095_76a8604a.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/103_1a9c1597.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/106_79cd2f11.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/109_55e6a3a6.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/113_88285ddc.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/098_dc810e06.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/117_53090c93.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/114_93510099.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/123_aa627c32.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/130_73253408.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/116_6db06f4f.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/115_d5146709.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/140_f44f6551.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/141_407a2a44.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/139_bfd3aef5.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/151_45f67dc0.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/146_9facde35.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/134_b18969c3.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/167_a8c9cc93.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/166_7035db72.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/155_e8b53808.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/171_a0135da2.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/170_7a52ca69.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/154_5b5f8b71.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/159_f08480e4.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/160_c161a04a.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/174_88ebde94.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/180_6d598841.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/175_8bf98da4.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/184_ef809025.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/179_67250a03.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/187_d9fe9a61.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/190_9bc50b23.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/188_384a726a.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/172_1b0d1e67.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/191_f070f7f3.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/195_cb44f362.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/200_0b0a1cfe.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/193_e5a1ce73.jpg\n",
            "/content/drive/MyDrive/test_for_wrong/197_46657abc.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnVcJuFmsVtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sdbfmfkqsVqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eKUN-DOzsVoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sx8uyfFCsVmY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}